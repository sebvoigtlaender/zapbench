{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-LMa0_zRyiE"
      },
      "source": [
        "# FFN inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO9ixXAN7Hw-"
      },
      "outputs": [],
      "source": [
        "# Install the latest snapshot from the FFN repository.\n",
        "!pip install git+https://github.com/google/ffn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2BH-ACTDPgs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
        "\n",
        "# Ensure tensorstore does not attempt to use GCE credentials\n",
        "os.environ['GCE_METADATA_ROOT'] = 'metadata.google.internal.invalid'\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.config.set_visible_devices([], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j8v1nH_G9jh"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "\n",
        "from clu import checkpoint\n",
        "from connectomics.jax.models import convstack\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "from scipy.ndimage import label\n",
        "import tensorstore as ts\n",
        "\n",
        "from ffn.inference import inference\n",
        "from ffn.inference import inference_utils\n",
        "from ffn.inference import inference_pb2\n",
        "from ffn.inference import executor\n",
        "from ffn.inference import seed\n",
        "from ffn.training import model as ffn_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLbhWzo1HNjW"
      },
      "outputs": [],
      "source": [
        "# Check for GPU presence. If this fails, use \"Runtime \u003e Change runtime type\".\n",
        "assert jax.devices()[0].platform in ('gpu', 'tpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Odkxn5nyMNMA"
      },
      "outputs": [],
      "source": [
        "# Load dataset.\n",
        "context = ts.Context({'cache_pool': {'total_bytes_limit': 1_000_000_000}})\n",
        "anatomy_data = ts.open({\n",
        "    'driver': 'zarr3',\n",
        "    'kvstore': {'driver': 'gcs', 'bucket': 'zapbench-release'},\n",
        "    'path': 'volumes/20240930/anatomy_clahe_ffn/',},\n",
        "    read=True, context=context).result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dosI88JzMiR9"
      },
      "outputs": [],
      "source": [
        "# Load a subvolume for local processing.\n",
        "x0, y0, z0 = 740, 800, 80\n",
        "raw = anatomy_data[x0:x0+100, y0:y0+100, z0:z0+80].read().result()\n",
        "raw = np.transpose(raw, [2, 1, 0])  # xyz -\u003e zyx\n",
        "raw = (raw.astype(np.float32) - 0.5) / 1.  # normalize data for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlVzzzb0SYY2"
      },
      "outputs": [],
      "source": [
        "# Load sample model checkpoint.\n",
        "!gsutil cp gs://zapbench-release/ffn_checkpoints/20240930/ckpt-332* .\n",
        "\n",
        "ckpt = checkpoint.Checkpoint('')\n",
        "state = ckpt.load_state(state=None, checkpoint='ckpt-332')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh957IM9XfTR"
      },
      "outputs": [],
      "source": [
        "# Instantiate model.\n",
        "model = convstack.ResConvStack(convstack.ConvstackConfig(\n",
        "    depth=8,\n",
        "    padding='same',\n",
        "    use_layernorm=True))\n",
        "fov_size = 33, 33, 33\n",
        "model_info = ffn_model.ModelInfo(\n",
        "    deltas=(0, 0, 0),\n",
        "    pred_mask_size=fov_size,\n",
        "    input_seed_size=fov_size,\n",
        "    input_image_size=fov_size)\n",
        "\n",
        "@jax.jit\n",
        "def _apply_fn(data):\n",
        "  return model.apply({'params': state['params']}, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wugXTgtyS1aB"
      },
      "outputs": [],
      "source": [
        "# Instantiate inference.\n",
        "iface = executor.ExecutorInterface()\n",
        "counters = inference_utils.Counters()\n",
        "exc = executor.JAXExecutor(iface, model_info, _apply_fn, counters, 1)\n",
        "exc.start_server()\n",
        "\n",
        "options = inference_pb2.InferenceOptions(\n",
        "    init_activation=0.95,\n",
        "    pad_value=0.5,\n",
        "    move_threshold=0.6,\n",
        "    segment_threshold=0.5,\n",
        "    min_boundary_dist={'x': 2, 'y': 2, 'z': 1},\n",
        "    min_segment_size=100,\n",
        ")\n",
        "cv = inference.Canvas(\n",
        "    model_info,\n",
        "    exc.get_client(counters),\n",
        "    raw,\n",
        "    options,\n",
        "    voxel_size_zyx=(2, 2, 2)\n",
        ")\n",
        "policy = functools.partial(\n",
        "    seed.SequentialPolicies,\n",
        "    **{'policies': [['PolicyImagePeaks3D2D', {}], ['PolicyImagePeaks2DDisk', {}]]}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb2Y9eJTRDWC"
      },
      "outputs": [],
      "source": [
        "# Segment subvolume.\n",
        "cv.segment_all(seed_policy=policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGVmRSSY1PAO"
      },
      "outputs": [],
      "source": [
        "!pip install neuroglancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkJx8BAzZApX"
      },
      "outputs": [],
      "source": [
        "# Visualize results in neuroglancer.\n",
        "import neuroglancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIWzzhnQHVGv"
      },
      "outputs": [],
      "source": [
        "seg = cv.segmentation\n",
        "\n",
        "dimensions = neuroglancer.CoordinateSpace(\n",
        "    names=['x', 'y', 'z'],\n",
        "    units='nm',\n",
        "    scales=[1, 1, 1],\n",
        ")\n",
        "viewer = neuroglancer.Viewer()\n",
        "with viewer.txn() as s:\n",
        "  s.dimensions = dimensions\n",
        "  s.layers['raw'] = neuroglancer.ImageLayer(\n",
        "      source=neuroglancer.LocalVolume(np.transpose((raw).astype(np.float32), [2, 1, 0]),\n",
        "      dimensions))\n",
        "  s.layers['seg'] = neuroglancer.SegmentationLayer(\n",
        "      source=neuroglancer.LocalVolume(np.transpose(seg.astype(np.uint64), [2, 1, 0]),\n",
        "      dimensions),\n",
        "      segments=[s for s in np.unique(seg) if s \u003e 0])\n",
        "\n",
        "viewer"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
