{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjGO3YwWLzbx"
      },
      "source": [
        "This tutorial describes how to access datasets associated with ZAPBench with Python.\n",
        "\n",
        "Datasets are hosted on Google Cloud Storage in the `zapbench-release` bucket, see [dataset README for acknowledgements and license (CC-BY)](http://zapbench-release.storage.googleapis.com/volumes/README.html). Datasets that may be especially relevant include:\n",
        "\n",
        "- Functional activity volume (`gs://zapbench-release/volumes/20240930/raw`)\n",
        "- Functional anatomy volume (`gs://zapbench-release/volumes/20240930/anatomy`)\n",
        "- Aligned activity volume (`gs://zapbench-release/volumes/20240930/aligned`)\n",
        "- Aligned and normalized activity volume (`gs://zapbench-release/volumes/20240930/df_over_f`)\n",
        "- Annotations used for segmentation model training and eval (`gs://zapbench-release/volumes/20240930/annotations/...`)\n",
        "- Segmentation used to extract traces (`gs://zapbench-release/volumes/20240930/segmentation`)\n",
        "- Traces used for time-series forecasting (`gs://zapbench-release/volumes/20240930/traces`)\n",
        "\n",
        "Datasets can also be browsed and downloaded directly using [gsutil](https://cloud.google.com/storage/docs/gsutil), e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiM8zpVCNRuR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorstore as ts\n",
        "\n",
        "\n",
        "# Create handle to the remote dataset.\n",
        "# ds = ts.open({\n",
        "#     'open': True,\n",
        "#     # Datasets are generally stored in zarr v3 format ('zarr3').\n",
        "#     # There are a few exceptions, where v2 is used ('zarr').\n",
        "#     'driver': 'zarr3',\n",
        "#     # Path of the dataset we want to load.\n",
        "#     'kvstore': 'gs://zapbench-release/volumes/20240930/raw'\n",
        "# }).result()\n",
        "\n",
        "# # Display info about the dataset.\n",
        "# print(ds.schema)\n",
        "\n",
        "# # Fetch a xy-slice using the handle.\n",
        "# z, t = 36, 0\n",
        "# example_xy_slice = ds[:, :, z, t].read().result()\n",
        "\n",
        "# # Plot slice.\n",
        "# plt.figure(figsize=(6, 12))\n",
        "# plt.imshow(example_xy_slice)\n",
        "# plt.title(f'xy slice at {z=}, {t=}');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C7GdbAVWLR5"
      },
      "outputs": [],
      "source": [
        "# Create handle to the remote dataset.\n",
        "ds_traces = ts.open({\n",
        "    'open': True,\n",
        "    'driver': 'zarr3',\n",
        "    'kvstore': 'gs://zapbench-release/volumes/20240930/traces'\n",
        "}).result()\n",
        "\n",
        "ds_traces.schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_traces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEfTehhjW5Bg"
      },
      "source": [
        "As described in [the manuscript](https://openreview.net/pdf?id=oCHsDpyawq), the experiment is subdivided into multiple conditions. Using `zapbench.data_utils` we can get the per-condition bounds for indexing the trace matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lqmGYUeW38A"
      },
      "outputs": [],
      "source": [
        "from zapbench import constants\n",
        "from zapbench import data_utils\n",
        "\n",
        "# Print the indexing bounds per condition.\n",
        "# Note that we keep a minimal amount of \"padding\" between conditions.\n",
        "for condition_id, condition_name in enumerate(constants.CONDITION_NAMES):\n",
        "  inclusive_min, exclusive_max = data_utils.get_condition_bounds(condition_id)\n",
        "  print(f'{condition_name} has bounds [{inclusive_min}, {exclusive_max}).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-stosEzHX5yp"
      },
      "source": [
        "Using these bounds, we can get traces for any given condition, e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD9hsGS9X-Od"
      },
      "outputs": [],
      "source": [
        "condition_name = 'turning'\n",
        "\n",
        "# Use the bounds to plot the traces of one of the conditions.\n",
        "inclusive_min, exclusive_max = data_utils.get_condition_bounds(\n",
        "    constants.CONDITION_NAMES.index(condition_name))\n",
        "traces_condition = ds_traces[inclusive_min:exclusive_max, :].read().result()\n",
        "\n",
        "# Plot traces.\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "plt.title(f'traces for {condition_name} condition')\n",
        "im = plt.imshow(traces_condition.T, aspect=\"auto\")\n",
        "plt.xlabel('timestep')\n",
        "plt.ylabel('neuron')\n",
        "cbar = fig.colorbar(im)\n",
        "cbar.set_label(\"normalized activity (df/f)\")\n",
        "plt.show();\n",
        "\n",
        "# For training and testing, we will want to further adjust these bounds for\n",
        "# splits, see `help(data_utils.adjust_condition_bounds_for_split)`.\n",
        "# As this is covered in other notebooks, we will not do this here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "zapbench",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
