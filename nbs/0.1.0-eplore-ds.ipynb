{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjGO3YwWLzbx"
      },
      "source": [
        "This tutorial describes how to access datasets associated with ZAPBench with Python.\n",
        "\n",
        "Datasets are hosted on Google Cloud Storage in the `zapbench-release` bucket, see [dataset README for acknowledgements and license (CC-BY)](http://zapbench-release.storage.googleapis.com/volumes/README.html). Datasets that may be especially relevant include:\n",
        "\n",
        "- Functional activity volume (`gs://zapbench-release/volumes/20240930/raw`)\n",
        "- Functional anatomy volume (`gs://zapbench-release/volumes/20240930/anatomy`)\n",
        "- Aligned activity volume (`gs://zapbench-release/volumes/20240930/aligned`)\n",
        "- Aligned and normalized activity volume (`gs://zapbench-release/volumes/20240930/df_over_f`)\n",
        "- Annotations used for segmentation model training and eval (`gs://zapbench-release/volumes/20240930/annotations/...`)\n",
        "- Segmentation used to extract traces (`gs://zapbench-release/volumes/20240930/segmentation`)\n",
        "- Traces used for time-series forecasting (`gs://zapbench-release/volumes/20240930/traces`)\n",
        "\n",
        "Datasets can also be browsed and downloaded directly using [gsutil](https://cloud.google.com/storage/docs/gsutil), e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QiM8zpVCNRuR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorstore as ts\n",
        "\n",
        "\n",
        "# Create handle to the remote dataset.\n",
        "# ds = ts.open({\n",
        "#     'open': True,\n",
        "#     # Datasets are generally stored in zarr v3 format ('zarr3').\n",
        "#     # There are a few exceptions, where v2 is used ('zarr').\n",
        "#     'driver': 'zarr3',\n",
        "#     # Path of the dataset we want to load.\n",
        "#     'kvstore': 'gs://zapbench-release/volumes/20240930/raw'\n",
        "# }).result()\n",
        "\n",
        "# # Display info about the dataset.\n",
        "# print(ds.schema)\n",
        "\n",
        "# # Fetch a xy-slice using the handle.\n",
        "# z, t = 36, 0\n",
        "# example_xy_slice = ds[:, :, z, t].read().result()\n",
        "\n",
        "# # Plot slice.\n",
        "# plt.figure(figsize=(6, 12))\n",
        "# plt.imshow(example_xy_slice)\n",
        "# plt.title(f'xy slice at {z=}, {t=}');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2C7GdbAVWLR5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0410 20:53:18.229642 21821133 google_auth_provider.cc:188] Could not find the credentials file in the standard gcloud location [/Users/s/.config/gcloud/application_default_credentials.json]. You may specify a credentials file using $GOOGLE_APPLICATION_CREDENTIALS, or to use Google application default credentials, run: gcloud auth application-default login\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Schema({\n",
              "  'chunk_layout': {\n",
              "    'grid_origin': [0, 0],\n",
              "    'inner_order': [0, 1],\n",
              "    'read_chunk': {'shape': [512, 512]},\n",
              "    'write_chunk': {'shape': [512, 512]},\n",
              "  },\n",
              "  'codec': {\n",
              "    'codecs': [{'configuration': {'endian': 'little'}, 'name': 'bytes'}],\n",
              "    'driver': 'zarr3',\n",
              "  },\n",
              "  'domain': {'exclusive_max': [[7879], [71721]], 'inclusive_min': [0, 0]},\n",
              "  'dtype': 'float32',\n",
              "  'fill_value': 0.0,\n",
              "  'rank': 2,\n",
              "})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create handle to the remote dataset.\n",
        "ds_traces = ts.open({\n",
        "    'open': True,\n",
        "    'driver': 'zarr3',\n",
        "    'kvstore': 'gs://zapbench-release/volumes/20240930/traces'\n",
        "}).result()\n",
        "\n",
        "ds_traces.schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorStore({\n",
              "  'context': {\n",
              "    'cache_pool': {},\n",
              "    'data_copy_concurrency': {},\n",
              "    'gcs_request_concurrency': {},\n",
              "    'gcs_request_retries': {},\n",
              "    'gcs_user_project': {},\n",
              "  },\n",
              "  'driver': 'zarr3',\n",
              "  'dtype': 'float32',\n",
              "  'kvstore': {\n",
              "    'bucket': 'zapbench-release',\n",
              "    'driver': 'gcs',\n",
              "    'path': 'volumes/20240930/traces/',\n",
              "  },\n",
              "  'metadata': {\n",
              "    'chunk_grid': {\n",
              "      'configuration': {'chunk_shape': [512, 512]},\n",
              "      'name': 'regular',\n",
              "    },\n",
              "    'chunk_key_encoding': {'name': 'default'},\n",
              "    'codecs': [{'configuration': {'endian': 'little'}, 'name': 'bytes'}],\n",
              "    'data_type': 'float32',\n",
              "    'fill_value': 0.0,\n",
              "    'node_type': 'array',\n",
              "    'shape': [7879, 71721],\n",
              "    'zarr_format': 3,\n",
              "  },\n",
              "  'transform': {\n",
              "    'input_exclusive_max': [[7879], [71721]],\n",
              "    'input_inclusive_min': [0, 0],\n",
              "  },\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_traces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEfTehhjW5Bg"
      },
      "source": [
        "As described in [the manuscript](https://openreview.net/pdf?id=oCHsDpyawq), the experiment is subdivided into multiple conditions. Using `zapbench.data_utils` we can get the per-condition bounds for indexing the trace matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8lqmGYUeW38A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gain has bounds [1, 648).\n",
            "dots has bounds [650, 2421).\n",
            "flash has bounds [2423, 3077).\n",
            "taxis has bounds [3079, 3734).\n",
            "turning has bounds [3736, 5046).\n",
            "position has bounds [5048, 5637).\n",
            "open loop has bounds [5639, 6622).\n",
            "rotation has bounds [6624, 7278).\n",
            "dark has bounds [7280, 7878).\n"
          ]
        }
      ],
      "source": [
        "from zapbench import constants\n",
        "from zapbench import data_utils\n",
        "\n",
        "# Print the indexing bounds per condition.\n",
        "# Note that we keep a minimal amount of \"padding\" between conditions.\n",
        "for condition_id, condition_name in enumerate(constants.CONDITION_NAMES):\n",
        "  inclusive_min, exclusive_max = data_utils.get_condition_bounds(condition_id)\n",
        "  print(f'{condition_name} has bounds [{inclusive_min}, {exclusive_max}).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'zapbench.constants' from '/Users/s/git/zapbench/zapbench/constants.py'>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-stosEzHX5yp"
      },
      "source": [
        "Using these bounds, we can get traces for any given condition, e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD9hsGS9X-Od"
      },
      "outputs": [],
      "source": [
        "condition_name = 'turning'\n",
        "\n",
        "# Use the bounds to plot the traces of one of the conditions.\n",
        "inclusive_min, exclusive_max = data_utils.get_condition_bounds(\n",
        "    constants.CONDITION_NAMES.index(condition_name))\n",
        "traces_condition = ds_traces[inclusive_min:exclusive_max, :].read().result()\n",
        "\n",
        "# Plot traces.\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "plt.title(f'traces for {condition_name} condition')\n",
        "im = plt.imshow(traces_condition.T, aspect=\"auto\")\n",
        "plt.xlabel('timestep')\n",
        "plt.ylabel('neuron')\n",
        "cbar = fig.colorbar(im)\n",
        "cbar.set_label(\"normalized activity (df/f)\")\n",
        "plt.show();\n",
        "\n",
        "# For training and testing, we will want to further adjust these bounds for\n",
        "# splits, see `help(data_utils.adjust_condition_bounds_for_split)`.\n",
        "# As this is covered in other notebooks, we will not do this here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "zapbench",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
