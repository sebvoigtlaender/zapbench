{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections.abc import Sequence\n",
    "\n",
    "import flax.jax_utils as flax_utils\n",
    "import flax.linen as nn\n",
    "import grain.python as grain\n",
    "import jax\n",
    "import numpy as np\n",
    "from absl import logging\n",
    "from connectomics.jax import checkpoint, training\n",
    "from etils import epath\n",
    "from orbax import checkpoint as ocp\n",
    "\n",
    "import zapbench.models.util as model_util\n",
    "from zapbench.ts_forecasting import heads, input_pipeline, train\n",
    "from zapbench.ts_forecasting.configs import infer, linear\n",
    "\n",
    "\n",
    "def _get_checkpoint_step(\n",
    "    checkpoint_manager: ocp.CheckpointManager,\n",
    "    selection_strategy: str,\n",
    ") -> int | None:\n",
    "  \"\"\"Returns the checkpoint step to use given a selection strategy.\n",
    "\n",
    "  Args:\n",
    "    checkpoint_manager: Checkpoint manager.\n",
    "    selection_strategy: Checkpoint selection strategy, can be 'early_stopping',\n",
    "      'best_val_loss', or 'latest'.\n",
    "\n",
    "  Returns:\n",
    "    Checkpoint step.\n",
    "  \"\"\"\n",
    "  if selection_strategy == 'early_stopping':\n",
    "    checkpointed_state = dict(\n",
    "        early_stop=None,\n",
    "    )\n",
    "    checkpointed_state = checkpoint.restore_checkpoint(\n",
    "        checkpoint_manager,\n",
    "        state=checkpointed_state,\n",
    "        step=checkpoint_manager.latest_step(),\n",
    "    )\n",
    "    return checkpointed_state['early_stop']['best_step']\n",
    "  elif selection_strategy == 'best_val_loss':\n",
    "    checkpointed_state = dict(\n",
    "        track_best_val_loss_step=None,\n",
    "    )\n",
    "    checkpointed_state = checkpoint.restore_checkpoint(\n",
    "        checkpoint_manager,\n",
    "        state=checkpointed_state,\n",
    "        step=checkpoint_manager.latest_step(),\n",
    "    )\n",
    "    return checkpointed_state['track_best_val_loss_step']['best_step']\n",
    "  elif selection_strategy == 'latest':\n",
    "    return checkpoint_manager.latest_step()\n",
    "  else:\n",
    "    raise ValueError(f'Unknown checkpoint selection: {selection_strategy}')\n",
    "\n",
    "\n",
    "def infer_single_step(\n",
    "    model: nn.Module,\n",
    "    head: heads.Head,\n",
    "    train_state: train.TrainState,\n",
    "    data_source: grain.RandomAccessDataSource,\n",
    "    idx: int,\n",
    "    infer_key: jax.Array,  # pylint: disable=unused-argument\n",
    "    covariates: Sequence[str] = (),\n",
    "    covariates_static: jax.Array | None = None,\n",
    "    with_carry: bool = False,\n",
    ") -> tuple[jax.Array, jax.Array]:\n",
    "  \"\"\"Runs independent inference on each index in the test set.\n",
    "\n",
    "  Returns:\n",
    "    prediction: prediction array\n",
    "    target: target array\n",
    "  \"\"\"\n",
    "  carry = None\n",
    "\n",
    "  batch = data_source[idx]\n",
    "  if 'covariates_static' in covariates:\n",
    "    batch['covariates_static'] = covariates_static\n",
    "\n",
    "  out = train.pred_step(\n",
    "      model,\n",
    "      train_state,\n",
    "      batch,\n",
    "      covariates,\n",
    "      initial_carry=carry,\n",
    "      return_carry=with_carry,\n",
    "  )\n",
    "\n",
    "  if not with_carry:\n",
    "    dist = head.get_distribution(out)\n",
    "  else:\n",
    "    carry, dist = out[0], head.get_distribution(out[1])\n",
    "\n",
    "  prediction = dist.mode()\n",
    "  target = batch['timeseries_output']\n",
    "\n",
    "  return prediction, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_workdir = '/Users/s/vault/zapbench/train_subject_14'\n",
    "exp_config = model_util.load_config(os.path.join(exp_workdir, 'config.json'))\n",
    "\n",
    "model = model_util.model_from_config(exp_config)\n",
    "\n",
    "covariates_static = input_pipeline.get_static_covariates(exp_config)\n",
    "\n",
    "checkpoint_manager = checkpoint.get_checkpoint_manager(\n",
    "    exp_workdir,\n",
    "    item_names=(\n",
    "        'early_stop',\n",
    "        'train_state',\n",
    "        'track_best_val_loss_step',\n",
    "    ),\n",
    ")\n",
    "\n",
    "step = _get_checkpoint_step(checkpoint_manager, 'best_val_loss')\n",
    "\n",
    "checkpointed_state = dict(\n",
    "    train_state=None,\n",
    ")\n",
    "checkpointed_state = checkpoint.restore_checkpoint(\n",
    "    checkpoint_manager,\n",
    "    state=checkpointed_state,\n",
    "    step=step,\n",
    ")\n",
    "train_state = checkpointed_state['train_state']\n",
    "train_state = train.TrainState(\n",
    "    **train_state\n",
    ")\n",
    "train_state = flax_utils.replicate(train_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "infer_config = infer.get_config()\n",
    "config = linear.get_config()\n",
    "config.update(infer_config)\n",
    "\n",
    "head = heads.create_head(config)\n",
    "rng = training.get_rng(config.seed)\n",
    "rng, infer_rng = jax.random.split(rng)\n",
    "infer_source = input_pipeline.create_inference_source_with_transforms(config)\n",
    "infer_key = jax.random.fold_in(key=infer_rng, data=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for infer_idx_set in config.infer_idx_sets:\n",
    "  name, idx_list = (infer_idx_set[k] for k in ('name', 'idx_list'))\n",
    "  infer_metrics = None\n",
    "  train_state = train.merge_batch_stats(train_state)\n",
    "  for i, idx in enumerate(idx_list):\n",
    "    prediction, target = infer_single_step(\n",
    "        model,\n",
    "        head,\n",
    "        flax_utils.unreplicate(train_state),\n",
    "        infer_source,\n",
    "        idx,\n",
    "        infer_key=infer_key,\n",
    "        covariates=tuple(config.covariates),\n",
    "        covariates_static=covariates_static,\n",
    "        with_carry=config.infer_with_carry,\n",
    "    )\n",
    "\n",
    "    if f'infer_{name}' in head.metrics:\n",
    "      metrics_update = head.metrics[\n",
    "          f'infer_{name}'\n",
    "      ].single_from_model_output(predictions=prediction, targets=target)\n",
    "      infer_metrics = (\n",
    "          metrics_update\n",
    "          if infer_metrics is None\n",
    "          else infer_metrics.merge(metrics_update)\n",
    "      )\n",
    "\n",
    "  if infer_metrics is not None:\n",
    "    infer_metrics_cpu = jax.tree.map(np.array, infer_metrics.compute())\n",
    "    print(infer_metrics_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.use(['nature', 'no-latex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_neuron_list = range(0, 10000, 500)\n",
    "\n",
    "for i_neuron in i_neuron_list:\n",
    "  fig, ax = plt.subplots(figsize=(4, 1), dpi=200)\n",
    "  ax.plot(prediction[0, :, i_neuron])\n",
    "  ax.plot(target[0, :, i_neuron])\n",
    "  ax.set_ylim(0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_target(target, window_size=10):\n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    smoothed = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode='valid'), axis=1, arr=target)\n",
    "    return smoothed\n",
    "\n",
    "target_smoothed = smooth_target(target, window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_neuron in i_neuron_list:\n",
    "  fig, ax = plt.subplots(figsize=(4, 1), dpi=200)\n",
    "  ax.plot(prediction[0, :, i_neuron])\n",
    "  ax.plot(target_smoothed[0, :, i_neuron])\n",
    "  ax.set_ylim(0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "abs_diff = np.abs(prediction - target)[0, :, :]\n",
    "plt.figure(figsize=(5, 5), dpi=200)\n",
    "plt.imshow(abs_diff.T, aspect='auto', cmap='magma', origin='lower', vmin=0, vmax=0.2)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zapbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
