{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections.abc import Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import flax.jax_utils as flax_utils\n",
    "import flax.linen as nn\n",
    "import grain.python as grain\n",
    "import jax\n",
    "import numpy as np\n",
    "from absl import logging\n",
    "from connectomics.jax import checkpoint, training\n",
    "from etils import epath\n",
    "from orbax import checkpoint as ocp\n",
    "\n",
    "import zapbench.models.util as model_util\n",
    "from zapbench.ts_forecasting import heads, input_pipeline, train\n",
    "from zapbench.ts_forecasting.configs import infer, linear\n",
    "\n",
    "\n",
    "def _get_checkpoint_step(\n",
    "    checkpoint_manager: ocp.CheckpointManager,\n",
    "    selection_strategy: str,\n",
    ") -> int | None:\n",
    "  \"\"\"Returns the checkpoint step to use given a selection strategy.\n",
    "\n",
    "  Args:\n",
    "    checkpoint_manager: Checkpoint manager.\n",
    "    selection_strategy: Checkpoint selection strategy, can be 'early_stopping',\n",
    "      'best_val_loss', or 'latest'.\n",
    "\n",
    "  Returns:\n",
    "    Checkpoint step.\n",
    "  \"\"\"\n",
    "  if selection_strategy == 'early_stopping':\n",
    "    checkpointed_state = dict(\n",
    "        early_stop=None,\n",
    "    )\n",
    "    checkpointed_state = checkpoint.restore_checkpoint(\n",
    "        checkpoint_manager,\n",
    "        state=checkpointed_state,\n",
    "        step=checkpoint_manager.latest_step(),\n",
    "    )\n",
    "    return checkpointed_state['early_stop']['best_step']\n",
    "  elif selection_strategy == 'best_val_loss':\n",
    "    checkpointed_state = dict(\n",
    "        track_best_val_loss_step=None,\n",
    "    )\n",
    "    checkpointed_state = checkpoint.restore_checkpoint(\n",
    "        checkpoint_manager,\n",
    "        state=checkpointed_state,\n",
    "        step=checkpoint_manager.latest_step(),\n",
    "    )\n",
    "    return checkpointed_state['track_best_val_loss_step']['best_step']\n",
    "  elif selection_strategy == 'latest':\n",
    "    return checkpoint_manager.latest_step()\n",
    "  else:\n",
    "    raise ValueError(f'Unknown checkpoint selection: {selection_strategy}')\n",
    "\n",
    "\n",
    "def infer_single_step(\n",
    "    model: nn.Module,\n",
    "    head: heads.Head,\n",
    "    train_state: train.TrainState,\n",
    "    data_source: grain.RandomAccessDataSource,\n",
    "    idx: int,\n",
    "    infer_key: jax.Array,  # pylint: disable=unused-argument\n",
    "    covariates: Sequence[str] = (),\n",
    "    covariates_static: jax.Array | None = None,\n",
    "    with_carry: bool = False,\n",
    ") -> tuple[jax.Array, jax.Array]:\n",
    "  \"\"\"Runs independent inference on each index in the test set.\n",
    "\n",
    "  Returns:\n",
    "    prediction: prediction array\n",
    "    target: target array\n",
    "  \"\"\"\n",
    "  carry = None\n",
    "\n",
    "  batch = data_source[idx]\n",
    "  if 'covariates_static' in covariates:\n",
    "    batch['covariates_static'] = covariates_static\n",
    "\n",
    "  out = train.pred_step(\n",
    "      model,\n",
    "      train_state,\n",
    "      batch,\n",
    "      covariates,\n",
    "      initial_carry=carry,\n",
    "      return_carry=with_carry,\n",
    "  )\n",
    "\n",
    "  if not with_carry:\n",
    "    dist = head.get_distribution(out)\n",
    "  else:\n",
    "    carry, dist = out[0], head.get_distribution(out[1])\n",
    "\n",
    "  prediction = dist.mode()\n",
    "  target = batch['timeseries_output']\n",
    "\n",
    "  return prediction, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_workdir = '/Users/s/vault/zapbench/linear/05'\n",
    "exp_config = model_util.load_config(os.path.join(exp_workdir, 'config.json'))\n",
    "\n",
    "model = model_util.model_from_config(exp_config)\n",
    "\n",
    "covariates_static = input_pipeline.get_static_covariates(exp_config)\n",
    "\n",
    "checkpoint_manager = checkpoint.get_checkpoint_manager(\n",
    "    exp_workdir,\n",
    "    item_names=(\n",
    "        'early_stop',\n",
    "        'train_state',\n",
    "        'track_best_val_loss_step',\n",
    "    ),\n",
    ")\n",
    "\n",
    "step = _get_checkpoint_step(checkpoint_manager, 'best_val_loss')\n",
    "\n",
    "checkpointed_state = dict(\n",
    "    train_state=None,\n",
    ")\n",
    "checkpointed_state = checkpoint.restore_checkpoint(\n",
    "    checkpoint_manager,\n",
    "    state=checkpointed_state,\n",
    "    step=step,\n",
    ")\n",
    "train_state = checkpointed_state['train_state']\n",
    "train_state = train.TrainState(\n",
    "    **train_state\n",
    ")\n",
    "train_state = flax_utils.replicate(train_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "infer_config = infer.get_config()\n",
    "config = linear.get_config('dataset_name=subject_14')\n",
    "config.update(infer_config)\n",
    "\n",
    "head = heads.create_head(config)\n",
    "rng = training.get_rng(config.seed)\n",
    "rng, infer_rng = jax.random.split(rng)\n",
    "infer_source = input_pipeline.create_inference_source_with_transforms(config)\n",
    "infer_key = jax.random.fold_in(key=infer_rng, data=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_0, all_targets_0 = [], []\n",
    "all_predictions_32, all_targets_32 = [], []\n",
    "cumulative_abs_error = []\n",
    "target_varibility = []\n",
    "for infer_idx_set in config.infer_idx_sets:\n",
    "  name, idx_list = (infer_idx_set[k] for k in ('name', 'idx_list'))\n",
    "  infer_metrics = None\n",
    "  train_state = train.merge_batch_stats(train_state)\n",
    "  for i, idx in enumerate(idx_list):\n",
    "    prediction, target = infer_single_step(\n",
    "        model,\n",
    "        head,\n",
    "        flax_utils.unreplicate(train_state),\n",
    "        infer_source,\n",
    "        idx,\n",
    "        infer_key=infer_key,\n",
    "        covariates=tuple(config.covariates),\n",
    "        covariates_static=covariates_static,\n",
    "        with_carry=config.infer_with_carry,\n",
    "    )\n",
    "    # all_predictions_0.append(prediction[0,0])\n",
    "    # all_targets_0.append(target[0,0])\n",
    "    # all_predictions_32.append(prediction[0,31])\n",
    "    # all_targets_32.append(target[0,31])\n",
    "    cumulative_abs_error.append(np.abs(prediction[0,0]-target[0,0]))\n",
    "    target_varibility.append(target[0,0])\n",
    "\n",
    "    if f'infer_{name}' in head.metrics:\n",
    "      metrics_update = head.metrics[\n",
    "          f'infer_{name}'\n",
    "      ].single_from_model_output(predictions=prediction, targets=target)\n",
    "      infer_metrics = (\n",
    "          metrics_update\n",
    "          if infer_metrics is None\n",
    "          else infer_metrics.merge(metrics_update)\n",
    "      )\n",
    "  break\n",
    "  if infer_metrics is not None:\n",
    "    infer_metrics_cpu = jax.tree.map(np.array, infer_metrics.compute())\n",
    "    print(infer_metrics_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_predictions_0 = np.array(all_predictions_0)\n",
    "# all_targets_0 = np.array(all_targets_0)\n",
    "# all_predictions_32 = np.array(all_predictions_32)\n",
    "# all_targets_32 = np.array(all_targets_32)\n",
    "cumulative_abs_error = np.array(cumulative_abs_error)\n",
    "target_varibility = np.var(target_varibility, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'no-latex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_neuron_list = range(0, 10000, 500)\n",
    "\n",
    "for i_neuron in i_neuron_list:\n",
    "  print(i_neuron)\n",
    "  fig, ax = plt.subplots(figsize=(4, 1), dpi=200)\n",
    "  ax.plot(prediction[0, :, i_neuron])\n",
    "  ax.plot(target[0, :, i_neuron])\n",
    "  ax.set_ylim(0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_target(target, window_size=10):\n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    smoothed = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode='valid'), axis=1, arr=target)\n",
    "    return smoothed\n",
    "\n",
    "target_smoothed = smooth_target(target, window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_neuron in i_neuron_list:\n",
    "  fig, ax = plt.subplots(figsize=(4, 1), dpi=200)\n",
    "  ax.plot(prediction[0, :, i_neuron])\n",
    "  ax.plot(target_smoothed[0, :, i_neuron])\n",
    "  ax.set_ylim(0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_diff = np.abs(prediction - target)[0, :, :]\n",
    "plt.figure(figsize=(5, 5), dpi=200)\n",
    "plt.imshow(abs_diff.T, aspect='auto', cmap='magma', origin='lower', vmin=0, vmax=0.2)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show error on anatomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy, h5py\n",
    "\n",
    "reference_anat = scipy.io.loadmat('/Users/s/vault/neural_data/janelia/Additional_mat_files/ReferenceBrain.mat')\n",
    "\n",
    "PATH = \"/Users/s/vault/neural_data/janelia\"\n",
    "subject_id = 14\n",
    "\n",
    "h5_path = f\"{PATH}/subject_{subject_id:02d}\"\n",
    "print(h5_path)\n",
    "h5 = h5py.File(f\"{h5_path}/TimeSeries.h5\", \"r\")\n",
    "abs_ix = h5['absIX']\n",
    "abs_ix = (abs_ix[0] - 1).astype(int)\n",
    "\n",
    "mat_path = f\"{PATH}/subject_{subject_id:02d}/data_full.mat\"\n",
    "data_struct = scipy.io.loadmat(mat_path)['data'][0, 0]\n",
    "\n",
    "all_cell_coordinates = data_struct[8]\n",
    "coordinates = all_cell_coordinates[abs_ix]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(np.sum(reference_anat['anat_stack_norm'], axis=-1).T, cmap='gray')\n",
    "plt.scatter(coordinates[::][:, 0], coordinates[::][:, 1], c='red', s=0.2)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_deviation = np.abs(prediction[0]-target[0])\n",
    "abs_deviation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 500, 10):\n",
    "  fig, axs = plt.subplots(3, 1, figsize=(20, 10))\n",
    "  # Plot predictions\n",
    "  axs[0].imshow(np.sum(reference_anat['anat_stack_norm'], axis=-1).T, cmap='gray')\n",
    "  sc0 = axs[0].scatter(\n",
    "      coordinates[:, 0], coordinates[:, 1],\n",
    "      c=np.log(all_predictions[i]),\n",
    "      cmap='coolwarm',\n",
    "      s=0.1,\n",
    "      vmin=np.log(abs_deviation).min(),\n",
    "      vmax=np.log(abs_deviation).max()\n",
    "  )\n",
    "  axs[0].axis('off')\n",
    "\n",
    "  axs[1].imshow(np.sum(reference_anat['anat_stack_norm'], axis=-1).T, cmap='gray')\n",
    "  sc1 = axs[1].scatter(\n",
    "      coordinates[:, 0], coordinates[:, 1],\n",
    "      c=np.log(all_targets[i]),\n",
    "      cmap='coolwarm',\n",
    "      s=0.1,\n",
    "      vmin=np.log(abs_deviation).min(),\n",
    "      vmax=np.log(abs_deviation).max()\n",
    "  )\n",
    "  axs[1].axis('off')\n",
    "\n",
    "  axs[2].imshow(np.sum(reference_anat['anat_stack_norm'], axis=-1).T, cmap='gray')\n",
    "  sc1 = axs[2].scatter(\n",
    "      coordinates[:, 0], coordinates[:, 1],\n",
    "      c=np.log(np.abs(all_targets[i]-all_predictions[i])),\n",
    "      cmap='magma',\n",
    "      s=0.1,\n",
    "      vmin=np.log(abs_deviation).min(),\n",
    "      vmax=np.log(abs_deviation).max()\n",
    "  )\n",
    "  axs[2].axis('off')\n",
    "  plt.show()\n",
    "  clear_output(wait=True)\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error t=1 and t=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 100, 20):\n",
    "  fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "  axs[0].imshow(np.sum(reference_anat['anat_stack_norm'], axis=-1).T, cmap='gray')\n",
    "  sc0 = axs[0].scatter(\n",
    "      coordinates[:, 0], coordinates[:, 1],\n",
    "      c=np.log(np.abs(all_targets_0[i]-all_predictions_0[i])),\n",
    "      cmap='coolwarm',\n",
    "      s=0.1,\n",
    "      vmin=np.log(abs_deviation).min(),\n",
    "      vmax=np.log(abs_deviation).max()\n",
    "  )\n",
    "  axs[0].axis('off')\n",
    "\n",
    "  axs[1].imshow(np.sum(reference_anat['anat_stack_norm'], axis=-1).T, cmap='gray')\n",
    "  sc1 = axs[1].scatter(\n",
    "      coordinates[:, 0], coordinates[:, 1],\n",
    "      c=np.log(np.abs(all_targets_32[i]-all_predictions_32[i])),\n",
    "      cmap='coolwarm',\n",
    "      s=0.1,\n",
    "      vmin=np.log(abs_deviation).min(),\n",
    "      vmax=np.log(abs_deviation).max()\n",
    "  )\n",
    "  axs[1].axis('off')\n",
    "\n",
    "  plt.show()\n",
    "  clear_output(wait=True)\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative error t=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_abs_error.mean(0)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 5), dpi=300)\n",
    "axs.imshow(np.sum(reference_anat['anat_stack_norm'], axis=-1).T, cmap='gray')\n",
    "sc0 = axs.scatter(\n",
    "    coordinates[:, 0], coordinates[:, 1],\n",
    "    c=np.log(cumulative_abs_error.mean(0)),\n",
    "    cmap='Reds',\n",
    "    s=0.2,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.colorbar(sc0, ax=axs, fraction=0.025, pad=0.04, aspect=30, shrink=1.0).ax.tick_params(labelsize=18)\n",
    "plt.tight_layout()\n",
    "axs.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with average variability per region (ie, is the model error meaningless in the sense that it is just a reflection of the variability of the data?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(10, 5), dpi=300)\n",
    "axs.imshow(np.sum(reference_anat['anat_stack_norm'], axis=-1).T, cmap='gray')\n",
    "sc0 = axs.scatter(\n",
    "    coordinates[:, 0], coordinates[:, 1],\n",
    "    c=np.log(target_varibility),\n",
    "    cmap='coolwarm',\n",
    "    s=0.2,\n",
    ")\n",
    "plt.tight_layout()\n",
    "axs.set_title('Target variability', fontsize=25)\n",
    "axs.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# plot τ^(β-1) for β=0.1, 0.5, 0.7\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=300)\n",
    "\n",
    "# Define the range of β values\n",
    "betas = [0.1, 0.5]\n",
    "\n",
    "# Plot τ^(β-1) for each β\n",
    "for beta in betas:\n",
    "    tau = np.linspace(0.01, 10, 1000)\n",
    "    ax.plot(tau, tau**(beta-1), label=f'β={beta}')\n",
    "\n",
    "# Add labels and legend\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('τ', fontsize=20)\n",
    "ax.set_ylabel('τ^(β-1)', fontsize=20)\n",
    "ax.set_title('τ^(β-1) for different β', fontsize=25)\n",
    "ax.tick_params(labelsize=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zapbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
